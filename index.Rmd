---
title: "Practical Machine Learning Course Project "
author: "Jeff Jager"
date: "11/17/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Human Activity Recognition (HAR) Research Project

This Project predicts the performance of six subjects performing barbell curls. The performance is tracked with the 'classe' variable in the training dataset. The training dataset includes 159 variables including the outcome variable.
Fifty-four variables were chosen to build the model. Variables with a large number of missing values were discarded.  

The data was loaded and subsetted as follows:
```{r WLE dataset}

wle <- read.csv('pml-training.csv')

wle_vars <- c( "num_window", "roll_belt", "pitch_belt","yaw_belt", "total_accel_belt", "gyros_belt_x", "gyros_belt_y", "gyros_belt_z", "accel_belt_x", "accel_belt_y", "accel_belt_z", "magnet_belt_x", "magnet_belt_y", "magnet_belt_z", "roll_arm", "pitch_arm", "yaw_arm", "total_accel_arm", "gyros_arm_x", "gyros_arm_y", "gyros_arm_z", "accel_arm_x", "accel_arm_y", "accel_arm_z", "magnet_arm_x", "magnet_arm_y", "magnet_arm_z", "roll_dumbbell", "pitch_dumbbell", "yaw_dumbbell", "total_accel_dumbbell", "gyros_dumbbell_x", "gyros_dumbbell_y", 	"gyros_dumbbell_z", "accel_dumbbell_x", "accel_dumbbell_y", "accel_dumbbell_z", "magnet_dumbbell_x", "magnet_dumbbell_y", "magnet_dumbbell_z", "roll_forearm", "pitch_forearm", "yaw_forearm", "total_accel_forearm", "gyros_forearm_x", "gyros_forearm_y", "gyros_forearm_z", "accel_forearm_x", "accel_forearm_y", "accel_forearm_z", "magnet_forearm_x", "magnet_forearm_y", "magnet_forearm_z", "classe"
)

wle_subset <- wle[wle_vars]

head(wle_subset)

```

The training data was partitioned into a training and test data set, which should not be confused with the test data without the outcome variable that is used for the quiz submission. Seventy percent of the data was used to train the model and the remaining thirty percent was used to test. The following models were created:  
    1. Regression Tree with rpart,   
    2. Regression Tree with boosting using gbm and   
    3. Random Forest with 10 trees   
  
The single regression tree predicted 48% of the outcomes correctly and the gbm boosted model predicted 98% correct outcomes.  the Random Forest model proved to be the most accurate with 99% of the outcomes correctly predicted.  Given that the random forest model achieved a very high degree of accuracy, I did not feel it necessary to build additional models that used cross-validation.
```{r random forest model}
library(caret)
library(ggplot2)

inTrain <- createDataPartition(y=wle_subset$classe, p=0.70, list=FALSE)

training <- wle_subset[inTrain,]
testing <- wle_subset[-inTrain,]

modFit <- train(classe ~ ., method="rf", data=training, prox=FALSE, ntree=10, allowParallel=TRUE, localImp = TRUE)

modFit$finalModel

testPredict<- predict(modFit, testing)
```

The confusion matrix for the random forest model shows the following:
```{r confusion matrix}
confusionMatrix(testPredict, testing$classe)

```
As can be seen in the results from the confusion matrix, the random forest model produced very good results based on the predicted values of the test data set. Another point worth noting is that Microsoft's Open R was used to decrease processing time when building the models. 



```{r}
library(randomForestExplainer)

min_depth_frame <- min_depth_distribution(modFit$finalModel)
```

The following table shows the distribution of minimal depth and the mean depth for the ten most important variables. These are the variables that resulted in the greatest improvement to the model. Looking at the first row for the variable 'roll_belt', we can see (using the color chart) that it was not used in approximately 5 trees, appeared at depth one in three trees, depth two in two trees, and depth four in one tree for an average depth of 1.1. The occurances are approximated by reading the chart.
```{r}
plot_min_depth_distribution(min_depth_frame)
```

The importance of each variable was determined using the measure_importance function from the randomForestExplainer package. The ten most important variables based on the increase in accuracy are as follows:
```{r, results="hide"}
measure_importance(modFit$finalModel)
mea_imp <- measure_importance(modFit$finalModel, measures = c("mean_min_depth", "no_of_trees", "times_a_root", "accuracy_decrease"))
mea <- mea_imp[order(-mea_imp$accuracy_decrease),]
```

```{r}
head(mea, 10)
```

Using the same measure of importance, the ten least important variables are:
```{r, results="hide"}
mea_least <- mea_imp[order(mea_imp$accuracy_decrease),]
```

```{r}
head(mea_least, 10)

```




```{r submission, include=FALSE}

wle_test <- read.csv('pml-testing.csv')

wle_test_subset <- wle_test[wle_vars[-54]]

subPred <- predict(modFit, wle_test_subset)

head(subPred, 1)

```
